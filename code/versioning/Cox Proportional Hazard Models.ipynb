{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5013dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from lifelines import CoxPHFitter\n",
    "import numpy as np\n",
    "from lifelines import KaplanMeierFitter\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/relationships/relations_minified_versioning.csv')\n",
    "# Remove rows with any NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove dependencies that have the same start and end dates\n",
    "df = df[df['interval_start_days'] != df['interval_end_days']]\n",
    "## Data Preprocessing\n",
    "df['is_out_of_date'] = df['is_out_of_date'].map({'t': True, 'f': False})\n",
    "df['is_exposed'] = df['is_exposed'].map({'t': True, 'f': False})\n",
    "df['interval_start_days'] = pd.to_numeric(df['interval_start_days'], errors='coerce')\n",
    "df = df.dropna(subset=['interval_start_days'])\n",
    "df['interval_end_days'] = pd.to_numeric(df['interval_end_days'], errors='coerce') ##coerce the errors to drop /N (NA) value in data\n",
    "df = df.dropna(subset=['interval_end_days'])\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "df.head\n",
    "\n",
    "df.requirement_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98906b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa30a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting has effect on the model since the model expects the data for each individual together\n",
    "df.sort_values(by=['dependency_id', 'interval_start_days', 'interval_end_days'], inplace=True)\n",
    "print(df)\n",
    "print(df.requirement_type.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f42a16",
   "metadata": {},
   "source": [
    "## Visualizing the Dependency Requirement Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863c905",
   "metadata": {},
   "source": [
    "# Time Varying Cox Proportional Hazards Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/relationships/relations_minified_versioning.csv')\n",
    "\n",
    "## Data Preprocessing\n",
    "df['is_out_of_date'] = df['is_out_of_date'].map({'t': True, 'f': False})\n",
    "df['is_exposed'] = df['is_exposed'].map({'t': True, 'f': False})\n",
    "df['interval_start_days'] = pd.to_numeric(df['interval_start_days'], errors='coerce')\n",
    "df = df.dropna(subset=['interval_start_days'])\n",
    "df['interval_end_days'] = pd.to_numeric(df['interval_end_days'], errors='coerce') ##coerce the errors to drop /N (NA) value in data\n",
    "df = df.dropna(subset=['interval_end_days'])\n",
    "\n",
    "## must remove deependencies that have the start and end dates the same\n",
    "df = df[df['interval_start_days'] != df['interval_end_days']]\n",
    "\n",
    "\n",
    "df.requirement_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sort by dependency_id and time\n",
    "df_sorted = df.sort_values(by=['dependency_id', 'interval_start_days'])\n",
    "\n",
    "# Step 2: Add previous requirement_type per dependency\n",
    "df_sorted['prev_requirement_type'] = df_sorted.groupby('dependency_id')['requirement_type'].shift(1)\n",
    "\n",
    "# Step 3: Filter for transitions where type changed\n",
    "transitions = df_sorted[\n",
    "    (df_sorted['prev_requirement_type'] == 'floating-major') &\n",
    "    (df_sorted['requirement_type'] == 'pinning')\n",
    "]\n",
    "\n",
    "# Step 4: Count unique dependencies that made this transition\n",
    "num_deps_transitioned = transitions['dependency_id'].nunique()\n",
    "print(f\"Number of dependencies that transitioned from floating-major to pinning: {num_deps_transitioned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5854d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to convert the requirement_type column to a categorical type\n",
    "\n",
    "df['requirement_type'] = pd.Categorical(\n",
    "    df['requirement_type'],\n",
    "    categories=['pinning',        # This is the baseline for one-hot encoding\n",
    "                'floating-major', \n",
    "                'floating-minor',\n",
    "                'floating-patch',\n",
    "                'fixed-ranging',\n",
    "                'complex-expression',\n",
    "                'at-most',\n",
    "                'or-expression',\n",
    "                'not-expression'\n",
    "    ],\n",
    "    ordered=True\n",
    ")\n",
    "df = pd.get_dummies(df, columns=['requirement_type'], drop_first=True)\n",
    "\n",
    "# Sorting has effect on the model since the model expects the data for each individual together\n",
    "df.sort_values(by=['dependency_id', 'interval_start_days', 'interval_end_days'], inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d88b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column names \n",
    "print(\"Columns in the DataFrame:\")\n",
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a361896",
   "metadata": {},
   "source": [
    "## Testing for complete separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3aa0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = [\n",
    "    'requirement_type_floating-minor',\n",
    "    'requirement_type_floating-patch',\n",
    "    'requirement_type_fixed-ranging',\n",
    "    'requirement_type_floating-major',\n",
    "    #'requirement_type_pinning',\n",
    "    'requirement_type_complex-expression',\n",
    "    'requirement_type_at-most',\n",
    "    'requirement_type_or-expression',\n",
    "    'requirement_type_not-expression'\n",
    "]\n",
    "\n",
    "# Loop and print cross-tabs\n",
    "for cov in covariates:\n",
    "    print(f\"\\n=== Crosstab for: {cov} ===\")\n",
    "    ct = pd.crosstab(df[cov], df['is_out_of_date'])\n",
    "    print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43331249",
   "metadata": {},
   "source": [
    "## Model 1: is_out_of_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxTimeVaryingFitter\n",
    "# Select a subset of variables\n",
    "cols_to_keep = ['dependency_id', 'interval_start_days', 'interval_end_days', 'is_out_of_date',\n",
    "    'requirement_type_floating-major',\n",
    "    'requirement_type_floating-minor',\n",
    "    'requirement_type_floating-patch',\n",
    "    'requirement_type_fixed-ranging',\n",
    "    'requirement_type_complex-expression',\n",
    "    'requirement_type_at-most',\n",
    "    'requirement_type_or-expression',\n",
    "    'requirement_type_not-expression'\n",
    "]\n",
    "\n",
    "df_model_vul = df[cols_to_keep]\n",
    "\n",
    "ctv = CoxTimeVaryingFitter()\n",
    "ctv.fit(df_model_vul, id_col=\"dependency_id\", event_col=\"is_out_of_date\", \n",
    "       start_col=\"interval_start_days\", stop_col=\"interval_end_days\",\n",
    "       show_progress=True)\n",
    "ctv.print_summary()\n",
    "\n",
    "# Plot and set title\n",
    "ax = ctv.plot()\n",
    "ax.set_title(\"Cox Time-Varying Coefficients: Vulnerable Dependencies\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d574b5a",
   "metadata": {},
   "source": [
    "# **Model 2: is_exposed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba030704",
   "metadata": {},
   "source": [
    "## Testing for separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = [\n",
    "    'requirement_type_floating-minor',\n",
    "    'requirement_type_floating-patch',\n",
    "    'requirement_type_fixed-ranging',\n",
    "    'requirement_type_floating-major',\n",
    "    #'requirement_type_pinning',\n",
    "    'requirement_type_complex-expression',\n",
    "    'requirement_type_at-most',\n",
    "    'requirement_type_or-expression',\n",
    "    'requirement_type_not-expression'\n",
    "]\n",
    "\n",
    "# Loop and print cross-tabs\n",
    "for cov in covariates:\n",
    "    print(f\"\\n=== Crosstab for: {cov} ===\")\n",
    "    ct = pd.crosstab(df[cov], df['is_exposed'])\n",
    "    print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b8c2f3",
   "metadata": {},
   "source": [
    "## Testing at-most as a single predictor for is_exposed - causing model separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['dependency_id', 'interval_start_days', 'interval_end_days', 'is_exposed',\n",
    "   # 'requirement_type_floating-major',\n",
    "    'requirement_type_floating-minor',\n",
    "    'requirement_type_floating-patch',\n",
    "    'requirement_type_fixed-ranging',\n",
    "    'requirement_type_complex-expression',\n",
    "    'requirement_type_at-most',\n",
    "   # 'requirement_type_or-expression',\n",
    "   # 'requirement_type_not-expression'\n",
    "]\n",
    "\n",
    "df_model_vuln = df[cols_to_keep]\n",
    "\n",
    "test_cols = ['dependency_id', 'interval_start_days', 'interval_end_days', 'is_exposed', 'requirement_type_at-most']\n",
    "df_test = df_model_vuln[test_cols]\n",
    "\n",
    "ctv_test = CoxTimeVaryingFitter()\n",
    "try:\n",
    "    ctv_test.fit(df_test, id_col=\"dependency_id\", event_col=\"is_exposed\",\n",
    "                start_col=\"interval_start_days\", stop_col=\"interval_end_days\",\n",
    "                show_progress=True)\n",
    "    print(\"At-most works alone\")\n",
    "    ctv_test.print_summary()\n",
    "except Exception as e:\n",
    "    print(f\"At-most fails alone: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50643ed",
   "metadata": {},
   "source": [
    "## Showning potential quasi separation graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a851f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['dependency_id', 'interval_start_days', 'interval_end_days', 'is_exposed',\n",
    "   # 'requirement_type_floating-major',\n",
    "    'requirement_type_floating-minor',\n",
    "    'requirement_type_floating-patch',\n",
    "    'requirement_type_fixed-ranging',\n",
    "    'requirement_type_complex-expression',\n",
    "    'requirement_type_at-most',\n",
    "   # 'requirement_type_or-expression',\n",
    "   # 'requirement_type_not-expression'\n",
    "]\n",
    "\n",
    "df_model_vuln = df[cols_to_keep]\n",
    "# Check if at-most subjects cluster at specific time points\n",
    "at_most_events = df_model_vuln[\n",
    "    (df_model_vuln['requirement_type_at-most'] == 1) & \n",
    "    (df_model_vuln['is_exposed'] == 1)\n",
    "]\n",
    "\n",
    "print(\"At-most event timing distribution:\")\n",
    "print(at_most_events['interval_end_days'].describe())\n",
    "\n",
    "# Check for clustering\n",
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "# Plot all events\n",
    "all_events = df_model_vuln[df_model_vuln['is_exposed'] == 1]\n",
    "ax1.hist(all_events['interval_end_days'], bins=50, alpha=0.7, label='All events')\n",
    "ax1.set_title('All Events Over Time')\n",
    "ax1.set_xlabel('Days')\n",
    "\n",
    "# Plot at-most events\n",
    "ax2.hist(at_most_events['interval_end_days'], bins=20, alpha=0.7, color='red')\n",
    "ax2.set_title('At-Most Events Over Time')\n",
    "ax2.set_xlabel('Days')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for exact time clustering\n",
    "print(\"\\nMost common event times for at-most:\")\n",
    "print(at_most_events['interval_end_days'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f436ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['dependency_id', 'interval_start_days', 'interval_end_days', 'is_exposed',\n",
    "   # 'requirement_type_floating-major',\n",
    "    'requirement_type_floating-minor',\n",
    "    'requirement_type_floating-patch',\n",
    "    'requirement_type_fixed-ranging',\n",
    "    'requirement_type_complex-expression',\n",
    "   # 'requirement_type_at-most',\n",
    "   # 'requirement_type_or-expression',\n",
    "   # 'requirement_type_not-expression'\n",
    "]\n",
    "\n",
    "df_model_outdated = df[cols_to_keep]\n",
    "\n",
    "\n",
    "ctv = CoxTimeVaryingFitter()\n",
    "ctv.fit(df_model_outdated, id_col=\"dependency_id\", event_col=\"is_exposed\", \n",
    "       start_col=\"interval_start_days\", stop_col=\"interval_end_days\",\n",
    "       show_progress=True)\n",
    "ctv.print_summary()\n",
    "\n",
    "# Plot and set title\n",
    "ax = ctv.plot()\n",
    "ax.set_title(\"Cox Time-Varying Coefficients: Vulnerable Dependencies\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ad5ac2",
   "metadata": {},
   "source": [
    "## dependency outdated and vulnerability rates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd108d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of unique dependencies\n",
    "total_dependencies = df['dependency_id'].nunique()\n",
    "\n",
    "# Number of dependencies ever exposed\n",
    "exposed_dependencies = df[df['is_exposed'] == True]['dependency_id'].nunique()\n",
    "\n",
    "# Number of dependencies ever outdated\n",
    "outdated_dependencies = df[df['is_out_of_date'] == True]['dependency_id'].nunique()\n",
    "\n",
    "# Percentages\n",
    "exposure_rate = (exposed_dependencies / total_dependencies) * 100\n",
    "outdated_rate = (outdated_dependencies / total_dependencies) * 100\n",
    "\n",
    "# Output\n",
    "print(f\"Total unique dependencies: {total_dependencies}\")\n",
    "print(f\"Dependencies ever exposed: {exposed_dependencies} ({exposure_rate:.2f}%)\")\n",
    "print(f\"Dependencies ever outdated: {outdated_dependencies} ({outdated_rate:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
